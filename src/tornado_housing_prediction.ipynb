{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state  Five-Digit ZIP Code\n",
      "0    AL                35004\n",
      "1    AL                35005\n",
      "2    AL                35006\n",
      "3    AL                35007\n",
      "4    AL                35010\n"
     ]
    }
   ],
   "source": [
    "# Tornado data\n",
    "tornado_df = pd.read_csv(\"us_tornado_dataset_1950_2021.csv\")\n",
    "\n",
    "# HPI data\n",
    "hpi_df = pd.read_csv(\"united_states_housing.csv\")\n",
    "\n",
    "# ZIP to state mapping (downloaded from GitHub, or use a local file)\n",
    "zip_ref_df = pd.read_csv(\"zip_code_database.csv\", usecols=[\"zipcode\", \"state_abbr\"])\n",
    "zip_ref_df.columns = [\"state\", \"Five-Digit ZIP Code\"]\n",
    "zip_ref_df = zip_ref_df[zip_ref_df[\"Five-Digit ZIP Code\"].str.isnumeric()]\n",
    "zip_ref_df[\"Five-Digit ZIP Code\"] = zip_ref_df[\"Five-Digit ZIP Code\"].astype(int)\n",
    "\n",
    "print(zip_ref_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge HPI with ZIP-to-state mapping\n",
    "hpi_with_state_df = pd.merge(hpi_df, zip_ref_df, on=\"Five-Digit ZIP Code\", how=\"left\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "hpi_with_state_df = hpi_with_state_df.dropna(subset=[\"state\", \"HPI\"])\n",
    "\n",
    "# Aggregate: average HPI per state and year\n",
    "hpi_state_year_df = hpi_with_state_df.groupby([\"state\", \"Year\"])[\"HPI\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match for merging\n",
    "tornado_df = tornado_df.rename(columns={\"yr\": \"Year\", \"st\": \"state\"})\n",
    "\n",
    "# Optional: summarize tornadoes per state/year\n",
    "# e.g., aggregate total injuries, fatalities, avg magnitude, etc.\n",
    "agg_tornado_df = tornado_df.groupby([\"state\", \"Year\"]).agg({\n",
    "    \"mag\": \"mean\",\n",
    "    \"inj\": \"sum\",\n",
    "    \"fat\": \"sum\",\n",
    "    \"len\": \"mean\",\n",
    "    \"wid\": \"mean\"\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(agg_tornado_df, hpi_state_year_df, on=[\"state\", \"Year\"], how=\"inner\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state  Year       mag  inj  fat       len         wid         HPI\n",
      "0    AK  2004  0.000000    0    0  0.000000    0.000000  150.768000\n",
      "1    AK  2005  0.000000    0    0  0.000000    0.000000  166.564000\n",
      "2    AL  1989  1.043478  484   22  5.647826  123.869565  100.000000\n",
      "3    AL  1990  0.473684   74    0  1.831579   28.210526   99.140000\n",
      "4    AL  1991  0.500000   33    5  0.680000   56.900000  100.636667\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())\n",
    "X = merged_df.drop(columns=[\"HPI\", \"state\"])\n",
    "y = merged_df[\"HPI\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 89.0580995\ttest: 96.2345764\tbest: 96.2345764 (0)\ttotal: 4.24ms\tremaining: 21.2s\n",
      "100:\tlearn: 66.6895622\ttest: 79.3370020\tbest: 79.2720613 (95)\ttotal: 48.5ms\tremaining: 2.35s\n",
      "200:\tlearn: 59.8823987\ttest: 79.5399085\tbest: 78.8558579 (148)\ttotal: 93.2ms\tremaining: 2.23s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 78.85585785\n",
      "bestIteration = 148\n",
      "\n",
      "Shrink model to first 149 iterations.\n",
      "CatBoost Regressor (no past history, real data):\n",
      "R² score: 0.340\n",
      "Mean Absolute Error (MAE): 51.346\n",
      "Relative Error: 26.12%\n"
     ]
    }
   ],
   "source": [
    "#early stopping\n",
    "train_pool = Pool(X_train, y_train)\n",
    "val_pool = Pool(X_test, y_test)\n",
    "\n",
    "cat_model = CatBoostRegressor(\n",
    "     iterations=5000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    early_stopping_rounds=100,  # Stop if no improvement on test set\n",
    "    verbose=100,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "\n",
    "cat_model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "y_pred = cat_model.predict(X_test)\n",
    "\n",
    "print(\"CatBoost Regressor (no past history, real data):\")\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R² score: {r2:.3f}')\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error (MAE): {mae:.3f}')\n",
    "\n",
    "relative_error = mae / np.mean(y_test) * 100\n",
    "print(f'Relative Error: {relative_error:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 61.71, Baseline R²: -0.00\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "y_mean = np.full_like(y_test, y_train.mean())\n",
    "mae_baseline = mean_absolute_error(y_test, y_mean)\n",
    "r2_baseline = r2_score(y_test, y_mean)\n",
    "print(f\"Baseline MAE: {mae_baseline:.2f}, Baseline R²: {r2_baseline:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
