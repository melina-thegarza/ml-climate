{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3_9Si2GY9jrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2edbd5f-cc31-4aee-94e9-8306add046d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---PRECIPITATION DATA FOR MA---\n",
            "\n",
            "Prefiltered length: 39413\n",
            "           STATION           STATION_NAME  ELEVATION  LATITUDE  LONGITUDE  \\\n",
            "0      COOP:190408  BARRE FALLS DAM MA US      277.4  42.43333  -72.03333   \n",
            "1      COOP:190408  BARRE FALLS DAM MA US      277.4  42.43333  -72.03333   \n",
            "2      COOP:190408  BARRE FALLS DAM MA US      277.4  42.43333  -72.03333   \n",
            "3      COOP:190408  BARRE FALLS DAM MA US      277.4  42.43333  -72.03333   \n",
            "4      COOP:190408  BARRE FALLS DAM MA US      277.4  42.43333  -72.03333   \n",
            "...            ...                    ...        ...       ...        ...   \n",
            "39408  COOP:190736   BLUE HILL COOP MA US      190.5  42.21230  -71.11370   \n",
            "39409  COOP:190736   BLUE HILL COOP MA US      190.5  42.21230  -71.11370   \n",
            "39410  COOP:190736   BLUE HILL COOP MA US      190.5  42.21230  -71.11370   \n",
            "39411  COOP:190736   BLUE HILL COOP MA US      190.5  42.21230  -71.11370   \n",
            "39412  COOP:190736   BLUE HILL COOP MA US      190.5  42.21230  -71.11370   \n",
            "\n",
            "                 DATE    HPCP Measurement Flag Quality Flag  \n",
            "0      20070101 00:00  999.99                ]               \n",
            "1      20070101 01:00  999.99                [               \n",
            "2      20070201 00:00  999.99                ]               \n",
            "3      20070201 01:00  999.99                [               \n",
            "4      20070301 00:00  999.99                ]               \n",
            "...               ...     ...              ...          ...  \n",
            "39408  20120626 13:00    0.00                T               \n",
            "39409  20120626 14:00    0.00                T               \n",
            "39410  20120627 17:00    0.00                T               \n",
            "39411  20120629 08:00    0.00                T               \n",
            "39412  20120629 10:00    0.04                                \n",
            "\n",
            "[39413 rows x 9 columns]\n",
            "Filtered length: 39373\n",
            "       ELEVATION  LATITUDE  LONGITUDE                DATE  HPCP  hour  \\\n",
            "40         190.5   42.2123   -71.1137 2012-08-01 02:00:00  0.00     2   \n",
            "41         190.5   42.2123   -71.1137 2012-08-01 15:00:00  0.54    15   \n",
            "42         190.5   42.2123   -71.1137 2012-08-01 16:00:00  0.04    16   \n",
            "43         190.5   42.2123   -71.1137 2012-08-02 13:00:00  0.00    13   \n",
            "44         190.5   42.2123   -71.1137 2012-08-05 13:00:00  0.00    13   \n",
            "...          ...       ...        ...                 ...   ...   ...   \n",
            "39408      190.5   42.2123   -71.1137 2012-06-26 13:00:00  0.00    13   \n",
            "39409      190.5   42.2123   -71.1137 2012-06-26 14:00:00  0.00    14   \n",
            "39410      190.5   42.2123   -71.1137 2012-06-27 17:00:00  0.00    17   \n",
            "39411      190.5   42.2123   -71.1137 2012-06-29 08:00:00  0.00     8   \n",
            "39412      190.5   42.2123   -71.1137 2012-06-29 10:00:00  0.04    10   \n",
            "\n",
            "       day_of_week  month elevation_range  HPCP_lag  \n",
            "40               2      8          0-500m      0.00  \n",
            "41               2      8          0-500m      0.00  \n",
            "42               2      8          0-500m      0.54  \n",
            "43               3      8          0-500m      0.04  \n",
            "44               6      8          0-500m      0.00  \n",
            "...            ...    ...             ...       ...  \n",
            "39408            1      6          0-500m      0.50  \n",
            "39409            1      6          0-500m      0.00  \n",
            "39410            2      6          0-500m      0.00  \n",
            "39411            4      6          0-500m      0.00  \n",
            "39412            4      6          0-500m      0.00  \n",
            "\n",
            "[39373 rows x 10 columns]\n",
            "MODELING WITHOUT ELEVATION\n",
            "Training Regression Model...\n",
            "Decision Tree Mean Squared Error: 0.00956565965278861\n",
            "XGBoost Mean Squared Error: 0.005760223499990786\n",
            "Training Classification Model for Heavy Rain Prediction...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      7742\n",
            "           1       0.31      0.08      0.13       133\n",
            "\n",
            "    accuracy                           0.98      7875\n",
            "   macro avg       0.64      0.54      0.56      7875\n",
            "weighted avg       0.97      0.98      0.98      7875\n",
            "\n",
            "MODELING WITH ELEVATION\n",
            "Training Regression Model...\n",
            "Decision Tree Mean Squared Error: 0.01036024079852397\n",
            "XGBoost Mean Squared Error: 0.00567830522404923\n",
            "Training Classification Model for Heavy Rain Prediction...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      7742\n",
            "           1       0.26      0.08      0.12       133\n",
            "\n",
            "    accuracy                           0.98      7875\n",
            "   macro avg       0.62      0.54      0.55      7875\n",
            "weighted avg       0.97      0.98      0.98      7875\n",
            "\n",
            "------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, classification_report\n",
        "import xgboost as xgb\n",
        "\n",
        "# df = pd.read_csv('Weather Data (US).csv', nrows=1000)\n",
        "# print(df['PRCP'].isna().sum())\n",
        "# print(df.head())\n",
        "\n",
        "# df['PRCP'] = df['PRCP'].interpolate()\n",
        "# print(df.head())\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "def plot_per_station(df):\n",
        "    station_mapping = dict(zip(df['STATION'], df['STATION_NAME']))\n",
        "\n",
        "    for station in df['STATION'].unique():\n",
        "        station_data = df[df['STATION'] == station]\n",
        "        station_data['DATE'] = pd.to_datetime(station_data['DATE'], format='%Y%m%d %H:%M')\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(24, 10))\n",
        "\n",
        "        # plot 1: precipitation over time\n",
        "        axes[0, 0].plot(station_data['DATE'], station_data['HPCP'], label=f\"Precipitation for {station_mapping[station]}\", color=\"blue\")\n",
        "        axes[0, 0].set_title(f\"Precipitation over Time for {station_mapping[station]}\", fontsize=14)\n",
        "        axes[0, 0].set_xlabel(\"Date\")\n",
        "        axes[0, 0].set_ylabel(\"Precipitation (inches)\")\n",
        "        axes[0, 0].tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "        # plot 2: monthly precipitation (seasonal trend)\n",
        "        station_data['Month'] = station_data['DATE'].dt.month\n",
        "        monthly_precip = station_data.groupby('Month')['HPCP'].sum()\n",
        "        axes[0, 1].bar(monthly_precip.index, monthly_precip.values, color=\"green\")\n",
        "        axes[0, 1].set_title(f\"Monthly Precipitation for {station_mapping[station]}\", fontsize=14)\n",
        "        axes[0, 1].set_xlabel(\"Month\")\n",
        "        axes[0, 1].set_ylabel(\"Total Precipitation (inches)\")\n",
        "        axes[0, 1].set_xticks(np.arange(1, 13))\n",
        "\n",
        "        # Plot 3: Seasonal decomposition using seasonal_decompose\n",
        "        # Set 'DATE' as index for the seasonal_decompose function\n",
        "        station_data.set_index('DATE', inplace=True)\n",
        "\n",
        "        # Use seasonal_decompose for the HPCP column, assuming annual seasonality\n",
        "        result = seasonal_decompose(station_data['HPCP'], model='additive', period=365)  # period=365 for annual seasonality\n",
        "\n",
        "        # Plot the decomposition result\n",
        "        axes[1, 0].plot(result.observed, label=\"Observed Data\", color='blue')\n",
        "        axes[1, 0].set_title(f\"Observed Data (Precipitation) for {station_mapping[station]}\")\n",
        "        axes[1, 0].set_xlabel(\"Date\")\n",
        "        axes[1, 0].set_ylabel(\"Precipitation (inches)\")\n",
        "\n",
        "        axes[1, 1].plot(result.trend, label=\"Trend\", color='green')\n",
        "        axes[1, 1].set_title(f\"Trend Component for {station_mapping[station]}\")\n",
        "        axes[1, 1].set_xlabel(\"Date\")\n",
        "        axes[1, 1].set_ylabel(\"Precipitation (inches)\")\n",
        "\n",
        "        plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "        # plot 4: autocorrelation plot\n",
        "        # autocorrelation helps to see if there are any correlations with previous values (helpful for ARIMA models)\n",
        "        fig_acf, ax_acf = plt.subplots(figsize=(10, 6))\n",
        "        autocorrelation_plot(station_data['HPCP'], ax=ax_acf)\n",
        "        ax_acf.set_title(f\"Autocorrelation for {station_mapping[station]}\", fontsize=14)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def preprocess_for_ml(df):\n",
        "    df['DATE'] = pd.to_datetime(df['DATE'], format='%Y%m%d %H:%M')\n",
        "\n",
        "    #remove missing or invalid data for precipitation\n",
        "    df['HPCP'] = df['HPCP'].replace(999.99, np.nan)\n",
        "    df['HPCP'] = df['HPCP'].interpolate(method='linear')\n",
        "    df = df.dropna(subset=['HPCP'])\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    #create additional time-based features\n",
        "    df.loc[:, 'hour'] = df['DATE'].dt.hour\n",
        "    df.loc[:, 'day_of_week'] = df['DATE'].dt.dayofweek\n",
        "    df.loc[:, 'month'] = df['DATE'].dt.month\n",
        "\n",
        "    #create elevation binning feature(low, med, high)\n",
        "    bins = [0, 500, 1000, 2000, 3000, np.inf]\n",
        "    labels = ['0-500m', '500-1000m', '1000-2000m', '2000-3000m', '3000+m']\n",
        "    df.loc[:, 'elevation_range'] = pd.cut(df['ELEVATION'], bins=bins, labels=labels)\n",
        "\n",
        "\n",
        "    #drop cols for are not necessary\n",
        "    df = df.drop(columns=['STATION', 'STATION_NAME', 'Measurement Flag', 'Quality Flag'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_lag_features(df, lag=1):\n",
        "    df['HPCP_lag'] = df['HPCP'].shift(lag)\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "\n",
        "# decision tree and XGBoost regression models\n",
        "def train_regression_model(df, use_elevation=True):\n",
        "    #select features & target\n",
        "    features = ['LATITUDE', 'LONGITUDE', 'hour', 'day_of_week', 'month', 'HPCP_lag']\n",
        "    if use_elevation:\n",
        "        features.append('ELEVATION')\n",
        "    X = df[features]\n",
        "    y = df['HPCP']\n",
        "\n",
        "    #split dataset into training & test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "    #model 1: decision tree regressor\n",
        "    dt_model = DecisionTreeRegressor(random_state=42)\n",
        "    dt_model.fit(X_train, y_train)\n",
        "    #predict on dataset\n",
        "    y_pred = dt_model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Decision Tree Mean Squared Error: {mse}\")\n",
        "\n",
        "    #model 2: XGBoost Regressor\n",
        "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    #predict on dataset\n",
        "    y_pred_xgb = xgb_model.predict(X_test)\n",
        "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "    print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
        "\n",
        "\n",
        "# classification model for heavy rain prediction\n",
        "def classify_heavy_rain(df, threshold=0.3, use_elevation=True):\n",
        "  # binary target: 1 for heavy rain (precip > threshold), 0 for no heavy rain\n",
        "    df['heavy_rain'] = (df['HPCP'] > threshold).astype(int)\n",
        "    features = ['LATITUDE', 'LONGITUDE', 'hour', 'day_of_week', 'month', 'HPCP_lag']\n",
        "    if use_elevation:\n",
        "        features.append('ELEVATION')\n",
        "    X = df[features]\n",
        "    y = df['heavy_rain']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Model: XGBoost Classifier\n",
        "    xgb_class_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "    xgb_class_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_class = xgb_class_model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(classification_report(y_test, y_pred_class))\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"---PRECIPITATION DATA FOR MA---\\n\")\n",
        "    #load & preprocess data\n",
        "    #change this based on local or in drive, but will always refer to precipitation_data.csv\n",
        "    df = pd.read_csv('/content/drive/MyDrive/precipitation_data.csv')\n",
        "    print(f\"Prefiltered length: {len(df)}\")\n",
        "    print(df)\n",
        "\n",
        "    cleaned_df = preprocess_for_ml(df)\n",
        "    # plot_per_station(cleaned_df)\n",
        "    cleaned_df = add_lag_features(cleaned_df)\n",
        "\n",
        "    print(f\"Filtered length: {len(cleaned_df)}\")\n",
        "    print(cleaned_df)\n",
        "\n",
        "    #modeling without elevation feature\n",
        "    print(\"MODELING WITHOUT ELEVATION\")\n",
        "\n",
        "    print(\"Training Regression Model...\")\n",
        "    train_regression_model(cleaned_df, use_elevation=False)\n",
        "\n",
        "    print(\"Training Classification Model for Heavy Rain Prediction...\")\n",
        "    classify_heavy_rain(cleaned_df, threshold=0.3, use_elevation=False)\n",
        "\n",
        "    #modeling with elevation feature\n",
        "    print(\"MODELING WITH ELEVATION\")\n",
        "\n",
        "    print(\"Training Regression Model...\")\n",
        "    train_regression_model(cleaned_df)\n",
        "\n",
        "    print(\"Training Classification Model for Heavy Rain Prediction...\")\n",
        "    classify_heavy_rain(cleaned_df, threshold=0.3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"------------------------\\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}